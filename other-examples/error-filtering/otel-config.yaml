receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 10s
    send_batch_size: 1024

  # Memory limiter to prevent OOM
  memory_limiter:
    check_interval: 1s
    limit_mib: 512

  # ============================================================
  # TRACE TRANSFORMATION
  # Transform specific error types so they don't contribute to error counts
  # while still sending the telemetry to New Relic for visibility
  # ============================================================
  transform/traces:
    error_mode: ignore
    trace_statements:
      # Transform validation errors - change status from Error to Ok
      # This prevents them from contributing to error rate calculations
      - context: span
        conditions:
          - attributes["error.type"] == "validation"
          - IsMatch(env("FILTER_VALIDATION_ERRORS"), "true")
          - status.code == STATUS_CODE_ERROR
        statements:
          - set(status.code, STATUS_CODE_OK)
          - set(status.message, "Expected validation error (transformed)")
          - set(attributes["error.expected"], true)
          - set(attributes["error"], false)

      # Transform auth errors - change status from Error to Ok
      - context: span
        conditions:
          - attributes["error.type"] == "auth"
          - IsMatch(env("FILTER_AUTH_ERRORS"), "true")
          - status.code == STATUS_CODE_ERROR
        statements:
          - set(status.code, STATUS_CODE_OK)
          - set(status.message, "Expected auth error (transformed)")
          - set(attributes["error.expected"], true)
          - set(attributes["error"], false)

      # Redact potential PII from all error messages
      - context: span
        statements:
          - replace_pattern(status.message, "token=[A-Za-z0-9]+", "token=REDACTED")
          - replace_pattern(status.message, "password=[^ ]+", "password=REDACTED")

      # Add metadata to indicate this span was processed
      - context: span
        conditions:
          - attributes["error.expected"] == true
        statements:
          - set(attributes["telemetry.transformed"], true)
          - delete_key(attributes, "error.type")

  # ============================================================
  # LOG TRANSFORMATION
  # Transform logs by severity level and error type
  # Downgrade severity so they don't trigger alerts
  # ============================================================
  transform/logs:
    error_mode: ignore
    log_statements:
      # Downgrade WARN logs to INFO if configured
      - context: log
        conditions:
          - severity_text == "WARN"
          - IsMatch(env("FILTER_WARN_LOGS"), "true")
        statements:
          - set(severity_number, SEVERITY_NUMBER_INFO)
          - set(severity_text, "INFO")
          - set(attributes["severity.original"], "WARN")

      # Mark validation error logs as expected
      - context: log
        conditions:
          - attributes["error.type"] == "validation"
          - IsMatch(env("FILTER_VALIDATION_ERRORS"), "true")
        statements:
          - set(attributes["error.expected"], true)
          - set(severity_number, SEVERITY_NUMBER_INFO)
          - set(severity_text, "INFO")

      # Mark auth error logs as expected
      - context: log
        conditions:
          - attributes["error.type"] == "auth"
          - IsMatch(env("FILTER_AUTH_ERRORS"), "true")
        statements:
          - set(attributes["error.expected"], true)
          - set(severity_number, SEVERITY_NUMBER_INFO)
          - set(severity_text, "INFO")

      # Redact potential PII from log bodies
      - context: log
        statements:
          - replace_pattern(body, "token=[A-Za-z0-9]+", "token=REDACTED")
          - replace_pattern(body, "password=[^ ]+", "password=REDACTED")
          - replace_pattern(body, "email=[^ ]+", "email=REDACTED")

      # Add metadata to indicate processing
      - context: log
        conditions:
          - attributes["error.expected"] == true
        statements:
          - set(attributes["telemetry.transformed"], true)
          - delete_key(attributes, "error.type")

  # ============================================================
  # METRIC TRANSFORMATION
  # Transform error metrics so expected errors don't inflate error counts
  # ============================================================
  transform/metrics:
    error_mode: ignore
    metric_statements:
      # Mark validation error metrics as expected
      - context: datapoint
        conditions:
          - attributes["error.type"] == "validation"
          - IsMatch(env("FILTER_VALIDATION_ERRORS"), "true")
        statements:
          - set(attributes["error.expected"], true)

      # Mark auth error metrics as expected
      - context: datapoint
        conditions:
          - attributes["error.type"] == "auth"
          - IsMatch(env("FILTER_AUTH_ERRORS"), "true")
        statements:
          - set(attributes["error.expected"], true)

      # Add metadata to transformed metrics
      - context: datapoint
        conditions:
          - attributes["error.expected"] == true
        statements:
          - set(attributes["telemetry.transformed"], true)
          - delete_key(attributes, "error.type")

  # ============================================================
  # RESOURCE DETECTION
  # Add host and cloud metadata
  # ============================================================
  resourcedetection:
    detectors: [env, system, docker]
    timeout: 5s

exporters:
  # Export to New Relic via OTLP
  otlphttp:
    endpoint: ${env:NEW_RELIC_OTLP_ENDPOINT}
    headers:
      api-key: ${env:NEW_RELIC_API_KEY}
    compression: gzip

  # Debug exporter for local testing
  debug:
    verbosity: basic
    sampling_initial: 5
    sampling_thereafter: 200

extensions:
  health_check:
    endpoint: 0.0.0.0:13133

  pprof:
    endpoint: 0.0.0.0:1777

  zpages:
    endpoint: 0.0.0.0:55679

service:
  extensions: [health_check, pprof, zpages]

  pipelines:
    # Trace pipeline with transformation
    traces:
      receivers: [otlp]
      processors:
        - memory_limiter
        - transform/traces      # Transform expected errors and redact sensitive data
        - resourcedetection
        - batch
      exporters: [otlphttp, debug]

    # Log pipeline with transformation
    logs:
      receivers: [otlp]
      processors:
        - memory_limiter
        - transform/logs        # Transform expected errors and redact sensitive data
        - resourcedetection
        - batch
      exporters: [otlphttp, debug]

    # Metric pipeline with transformation
    metrics:
      receivers: [otlp]
      processors:
        - memory_limiter
        - transform/metrics     # Mark expected errors and add metadata
        - resourcedetection
        - batch
      exporters: [otlphttp, debug]

  telemetry:
    logs:
      level: info
    metrics:
      address: 0.0.0.0:8888