
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: collector-config
  namespace: nr-host-monitoring
  labels:
    app.kubernetes.io/name: collector-config
data:
  collector-config: |
    receivers:
      # Keep configuration in sync with: https://github.com/newrelic/nrdot-collector-releases/blob/main/distributions/nrdot-collector-host/config.yaml
      otlp:
        protocols:
          grpc:
          http:
            # By default, the otlp receiver is configured to listen on localhost at port 4318, we need to change this to listen on the pod IP.
            endpoint: ${env:MY_POD_IP}:4318
      
      hostmetrics:
        root_path: /hostfs
        # Default collection interval is 60s. Lower if you need finer granularity.
        collection_interval: 60s
        scrapers:
          cpu:
            metrics:
              system.cpu.time:
                enabled: false
              system.cpu.utilization:
                enabled: true
          load:
          memory:
            metrics:
              system.memory.utilization:
                enabled: true
          paging:
            metrics:
              system.paging.utilization:
                enabled: false
              system.paging.faults:
                enabled: false
          filesystem:
            metrics:
              system.filesystem.utilization:
                enabled: true
            # Reading /containers/services causes error running in docker.
            # Delete for production deployments.
            exclude_mount_points:
              mount_points: ["/containers/services"]
              match_type: strict
          disk:
            metrics:
              system.disk.merged:
                enabled: false
              system.disk.pending_operations:
                enabled: false
              system.disk.weighted_io_time:
                enabled: false
          network:
            metrics:
              system.network.connections:
                enabled: false
          # Uncomment to enable process metrics, which can be noisy but valuable.
          # processes:
          # process:
          #  metrics:
          #    process.cpu.utilization:
          #      enabled: true
          #    process.cpu.time:
          #      enabled: false
          # Mute various errors reading process metrics running locally in docker.
          # Delete for production deployments.
          #   mute_process_exe_error: true
          #   mute_process_user_error: true
          #   mute_process_io_error: true
    
      filelog:
        include:
          - /var/log/alternatives.log
          - /var/log/cloud-init.log
          - /var/log/auth.log
          - /var/log/dpkg.log
          - /var/log/syslog
          - /var/log/messages
          - /var/log/secure
          - /var/log/yum.log

    processors:    
      # group system.cpu metrics by cpu
      metricstransform:
        transforms:
          - include: system.cpu.utilization
            action: update
            operations:
              - action: aggregate_labels
                label_set: [ state ]
                aggregation_type: mean
          - include: system.paging.operations
            action: update
            operations:
              - action: aggregate_labels
                label_set: [ direction ]
                aggregation_type: sum

      # remove system.cpu metrics for states
      filter/exclude_cpu_utilization:
        metrics:
          datapoint:
            - 'metric.name == "system.cpu.utilization" and attributes["state"] == "interrupt"'
            - 'metric.name == "system.cpu.utilization" and attributes["state"] == "nice"'
            - 'metric.name == "system.cpu.utilization" and attributes["state"] == "softirq"'
      filter/exclude_memory_utilization:
        metrics:
          datapoint:
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "slab_unreclaimable"'
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "inactive"'
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "cached"'
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "buffered"'
            - 'metric.name == "system.memory.utilization" and attributes["state"] == "slab_reclaimable"'
      filter/exclude_memory_usage:
        metrics:
          datapoint:
            - 'metric.name == "system.memory.usage" and attributes["state"] == "slab_unreclaimable"'
            - 'metric.name == "system.memory.usage" and attributes["state"] == "inactive"'
      filter/exclude_filesystem_utilization:
        metrics:
          datapoint:
            - 'metric.name == "system.filesystem.utilization" and attributes["type"] == "squashfs"'
      filter/exclude_filesystem_usage:
        metrics:
          datapoint:
            - 'metric.name == "system.filesystem.usage" and attributes["type"] == "squashfs"'
            - 'metric.name == "system.filesystem.usage" and attributes["state"] == "reserved"'
      filter/exclude_filesystem_inodes_usage:
        metrics:
          datapoint:
            - 'metric.name == "system.filesystem.inodes.usage" and attributes["type"] == "squashfs"'
            - 'metric.name == "system.filesystem.inodes.usage" and attributes["state"] == "reserved"'
      filter/exclude_system_disk:
        metrics:
          datapoint:
            - 'metric.name == "system.disk.operations" and IsMatch(attributes["device"], "^loop.*") == true'
            - 'metric.name == "system.disk.merged" and IsMatch(attributes["device"], "^loop.*") == true'
            - 'metric.name == "system.disk.io" and IsMatch(attributes["device"], "^loop.*") == true'
            - 'metric.name == "system.disk.io_time" and IsMatch(attributes["device"], "^loop.*") == true'
            - 'metric.name == "system.disk.operation_time" and IsMatch(attributes["device"], "^loop.*") == true'
      filter/exclude_system_paging:
        metrics:
          datapoint:
            - 'metric.name == "system.paging.usage" and attributes["state"] == "cached"'
            - 'metric.name == "system.paging.operations" and attributes["type"] == "cached"'
      filter/exclude_network:
        metrics:
          datapoint:
            - 'IsMatch(metric.name, "^system.network.*") == true and attributes["device"] == "lo"'
      attributes/exclude_system_paging:
        include:
          match_type: strict
          metric_names:
            - system.paging.operations
        actions:
          - key: type
            action: delete
    
      cumulativetodelta:
    
      transform/host:
        metric_statements:
          - context: metric
            statements:
              - set(description, "")
              - set(unit, "")
    
      transform:
        trace_statements:
          - context: span
            statements:
              - truncate_all(attributes, 4095)
              - truncate_all(resource.attributes, 4095)
        log_statements:
          - context: log
            statements:
              - truncate_all(attributes, 4095)
              - truncate_all(resource.attributes, 4095)
    
      # used to prevent out of memory situations on the collector
      memory_limiter:
        check_interval: 1s
        limit_mib: ${env:NEW_RELIC_MEMORY_LIMIT_MIB:-100}
    
      batch:
    
      resourcedetection:
        detectors: ["system"]
        system:
          hostname_sources: ["os"]
          resource_attributes:
            host.id:
              enabled: true
    
      resourcedetection/cloud:
        detectors: ["gcp", "ec2", "azure"]
        timeout: 2s
        ec2:
          resource_attributes:
            host.name:
              enabled: false
    
      # Gives OTEL_RESOURCE_ATTRIBUTES precedence over other sources.
      # host.id is set from env whenever the collector is orchestrated by NR Agents.
      resourcedetection/env:
        detectors: ["env"]
        timeout: 2s
        override: true
    
    exporters:
      debug:
        verbosity: detailed
      otlphttp/newrelic:
        endpoint: ${env:NEW_RELIC_OTLP_ENDPOINT:-https://otlp.nr-data.net}
        headers:
          api-key: ${env:NEW_RELIC_API_KEY}
    
    service:
      pipelines:
        metrics/host:
          receivers: [hostmetrics]
          processors:
            - memory_limiter
            - metricstransform
            - filter/exclude_cpu_utilization
            - filter/exclude_memory_utilization
            - filter/exclude_memory_usage
            - filter/exclude_filesystem_utilization
            - filter/exclude_filesystem_usage
            - filter/exclude_filesystem_inodes_usage
            - filter/exclude_system_disk
            - filter/exclude_network
            - attributes/exclude_system_paging
            - transform/host
            - resourcedetection
            - resourcedetection/cloud
            - resourcedetection/env
            - cumulativetodelta
            - batch
          exporters: [otlphttp/newrelic]
        logs/host:
          receivers: [filelog]
          processors: [transform, resourcedetection, resourcedetection/cloud, resourcedetection/env, batch]
          exporters: [otlphttp/newrelic]
        traces:
          receivers: [otlp]
          processors: [transform, resourcedetection, resourcedetection/cloud, resourcedetection/env, batch]
          exporters: [otlphttp/newrelic]
        metrics:
          receivers: [otlp]
          processors: [transform, resourcedetection, resourcedetection/cloud, resourcedetection/env, batch]
          exporters: [otlphttp/newrelic]
        logs:
          receivers: [otlp]
          processors: [transform, resourcedetection, resourcedetection/cloud, resourcedetection/env, batch]
          exporters: [otlphttp/newrelic]
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: collector
  namespace: nr-host-monitoring
  labels:
    app.kubernetes.io/name: collector
spec:
  selector:
    matchLabels:
      name: collector
  template:
    metadata:
      labels:
        name: collector
    spec:
      containers:
        - name: collector
          image: otel/opentelemetry-collector-contrib:0.122.1
          env:
            # The default US endpoint is set here. You can change the endpoint and port based on your requirements if needed.
            # docs: https://docs.newrelic.com/docs/more-integrations/open-source-telemetry-integrations/opentelemetry/best-practices/opentelemetry-otlp/#configure-endpoint-port-protocol
            - name: NEW_RELIC_OTLP_ENDPOINT
              value: https://otlp.nr-data.net/
            # The New Relic API key used to authenticate export requests.
            # Defined in secrets.yaml
            - name: NEW_RELIC_API_KEY
              valueFrom:
                secretKeyRef:
                  name: nr-host-monitoring-secret
                  key: NEW_RELIC_API_KEY
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            # host.id is required for NewRelic host entity synthesis and relationships, but is not included by any resourcedetection detector when running with docker on macOS.
            # We enabled the "env" resource detector and set host.id to the name of the node via env var.
            - name: OTEL_RESOURCE_ATTRIBUTES
              value: host.id=$(NODE_NAME)
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          volumeMounts:
            - name: collector-config-vol
              mountPath: /etc/otelcol-contrib
            - name: hostfs
              mountPath: /hostfs
              readOnly: true
              mountPropagation: HostToContainer
          ports:
            - containerPort: 4318
              hostPort: 4318
      volumes:
        - name: collector-config-vol
          configMap:
            name: collector-config
            items:
              - key: collector-config
                path: config.yaml
        - name: hostfs
          hostPath:
            path: /
